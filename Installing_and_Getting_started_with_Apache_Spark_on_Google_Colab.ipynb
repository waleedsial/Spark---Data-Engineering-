{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Installing and Getting started with Apache Spark on Google Colab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOD0XXz6vyE5/9bQjaABxG1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waleedsial/Spark---Data-Engineering-/blob/master/Installing_and_Getting_started_with_Apache_Spark_on_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drHkVo04rTRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Installing JVM\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Installing spark from spark website. \n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "\n",
        "# Unzipping \n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "\n",
        "# Let us allow to find the spark & set the path variable \n",
        "!pip install -q findspark\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6iMqCgEsIFg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9364ceb8-f697-4982-cacc-5771f70e01cf"
      },
      "source": [
        "# Lets see which jvms are present already\n",
        "!ls /usr/lib/jvm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "default-java\t\t   java-11-openjdk-amd64     java-8-openjdk-amd64\n",
            "java-1.11.0-openjdk-amd64  java-1.8.0-openjdk-amd64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ5ZB53gsPyL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a20442bb-74b0-4af2-d46b-c47e6acf0f98"
      },
      "source": [
        "!pip install -U pyarrow\n",
        "# Use Case: we would want to bring spark datafram into pandas dataframe \n",
        "# Python serialization is very slow \n",
        "# Pyarrow Apache Arrow is an in-memory columnar data format that is used in Spark to efficiently transfer data between JVM and Python processes.\n",
        "# https://spark.apache.org/docs/latest/sql-pyspark-pandas-with-arrow.html"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyarrow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/d2/695bab1e1e7a4554b6dbd287d55cca096214bd441037058a432afd724bb1/pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1MB)\n",
            "\u001b[K     |████████████████████████████████| 63.2MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.12.0)\n",
            "Installing collected packages: pyarrow\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed pyarrow-0.16.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLqmlLVHsyVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting env paths\n",
        "import os \n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bieWC44XtJtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://medium.com/@sushantgautam_930/apache-spark-in-google-collaboratory-in-3-steps-e0acbba654e6\n",
        "#https://www.youtube.com/watch?v=d9g9xbNc5qA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bJ6HlSdr95o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import findspark\n",
        "# finding spark & setting system path \n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "# In order to work in spark we need spark context \n",
        "\n",
        "# We are setting local since we dont have distributed nodes\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "spark.conf.set(\"spark.executor.memory\", \"4g\")\n",
        "spark.conf.set(\"spark.driver.memory\", \"4g\")\n",
        "spark.conf.set(\"spark.memory.fraction\", \"0.9\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjvliLVZuH1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing Spark \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrfZtCaTuM1Y",
        "colab_type": "text"
      },
      "source": [
        "#  **Testing Spark**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeUZTWkJrlO1",
        "colab_type": "text"
      },
      "source": [
        "Instructions are similar for local & collab. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5Cw6l4AuSgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, tempfile, urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VHm3g7QuVn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Settting a base directory \n",
        "BASE_DIR = '/tmp'\n",
        "# Setting output file for downloading credit data \n",
        "OUTPUT_FILE = os.path.join(BASE_DIR, 'credit_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro089Le5uhzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# downloading credit data \n",
        "credit_data = urllib.request.urlretrieve('https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data',OUTPUT_FILE )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCU6nf8IvB1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cde4d950-0c56-48b8-8d79-bd34b33388f8"
      },
      "source": [
        "!ls /tmp"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blockmgr-68cd3739-791f-4004-b027-f447c9360cf7\n",
            "credit_data.csv\n",
            "hsperfdata_root\n",
            "spark-72ccd5a3-7466-427b-9a8d-348202a7d50b\n",
            "spark-b52ce3d7-4186-4b8a-befe-624711e4cc9d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRjxDMiRvEtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the file \n",
        "# Inferring the schema \n",
        "credit_df = spark.read.option(\"inferSchema\", \"true\").csv(\"/tmp/credit_data.csv\", header = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeyEUVLlvWJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6dfac2e2-88e4-4269-c1c3-0b91ccb819a1"
      },
      "source": [
        "credit_df.head()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(_c0='b', _c1='30.83', _c2=0.0, _c3='u', _c4='g', _c5='w', _c6='v', _c7=1.25, _c8='t', _c9='t', _c10=1, _c11='f', _c12='g', _c13='00202', _c14=0, _c15='+')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwF45m0hvcrJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f9e47b2-a1d9-4f3c-cee1-057863f7fd0c"
      },
      "source": [
        "type(credit_df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5LJKSdivgGQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "7677d1ff-aa02-4202-9070-f0f1378026d8"
      },
      "source": [
        "credit_df.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+------+---+---+---+---+-----+---+---+----+----+----+-----+-----+----+\n",
            "|_c0|  _c1|   _c2|_c3|_c4|_c5|_c6|  _c7|_c8|_c9|_c10|_c11|_c12| _c13| _c14|_c15|\n",
            "+---+-----+------+---+---+---+---+-----+---+---+----+----+----+-----+-----+----+\n",
            "|  b|30.83|   0.0|  u|  g|  w|  v| 1.25|  t|  t|   1|   f|   g|00202|    0|   +|\n",
            "|  a|58.67|  4.46|  u|  g|  q|  h| 3.04|  t|  t|   6|   f|   g|00043|  560|   +|\n",
            "|  a|24.50|   0.5|  u|  g|  q|  h|  1.5|  t|  f|   0|   f|   g|00280|  824|   +|\n",
            "|  b|27.83|  1.54|  u|  g|  w|  v| 3.75|  t|  t|   5|   t|   g|00100|    3|   +|\n",
            "|  b|20.17| 5.625|  u|  g|  w|  v| 1.71|  t|  f|   0|   f|   s|00120|    0|   +|\n",
            "|  b|32.08|   4.0|  u|  g|  m|  v|  2.5|  t|  f|   0|   t|   g|00360|    0|   +|\n",
            "|  b|33.17|  1.04|  u|  g|  r|  h|  6.5|  t|  f|   0|   t|   g|00164|31285|   +|\n",
            "|  a|22.92|11.585|  u|  g| cc|  v| 0.04|  t|  f|   0|   f|   g|00080| 1349|   +|\n",
            "|  b|54.42|   0.5|  y|  p|  k|  h| 3.96|  t|  f|   0|   f|   g|00180|  314|   +|\n",
            "|  b|42.50| 4.915|  y|  p|  w|  v|3.165|  t|  f|   0|   t|   g|00052| 1442|   +|\n",
            "|  b|22.08|  0.83|  u|  g|  c|  h|2.165|  f|  f|   0|   t|   g|00128|    0|   +|\n",
            "|  b|29.92| 1.835|  u|  g|  c|  h|4.335|  t|  f|   0|   f|   g|00260|  200|   +|\n",
            "|  a|38.25|   6.0|  u|  g|  k|  v|  1.0|  t|  f|   0|   t|   g|00000|    0|   +|\n",
            "|  b|48.08|  6.04|  u|  g|  k|  v| 0.04|  f|  f|   0|   f|   g|00000| 2690|   +|\n",
            "|  a|45.83|  10.5|  u|  g|  q|  v|  5.0|  t|  t|   7|   t|   g|00000|    0|   +|\n",
            "|  b|36.67| 4.415|  y|  p|  k|  v| 0.25|  t|  t|  10|   t|   g|00320|    0|   +|\n",
            "|  b|28.25| 0.875|  u|  g|  m|  v| 0.96|  t|  t|   3|   t|   g|00396|    0|   +|\n",
            "|  a|23.25| 5.875|  u|  g|  q|  v| 3.17|  t|  t|  10|   f|   g|00120|  245|   +|\n",
            "|  b|21.83|  0.25|  u|  g|  d|  h|0.665|  t|  f|   0|   t|   g|00000|    0|   +|\n",
            "|  a|19.17| 8.585|  u|  g| cc|  h| 0.75|  t|  t|   7|   f|   g|00096|    0|   +|\n",
            "+---+-----+------+---+---+---+---+-----+---+---+----+----+----+-----+-----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}